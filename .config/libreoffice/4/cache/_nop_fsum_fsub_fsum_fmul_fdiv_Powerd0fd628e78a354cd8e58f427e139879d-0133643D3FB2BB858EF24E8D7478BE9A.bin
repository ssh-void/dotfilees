//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36361462
// Unknown Toolkit Version
// Based on NVVM 7.0.1
//

.version 9.0
.target sm_50, texmode_independent
.address_size 64

	// .globl	DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power

.entry DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power(
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_0,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_1,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_2,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_3,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_4,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_5,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_6,
	.param .f64 DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_7
)
{
	.reg .pred 	%p<134>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<75>;
	.reg .f64 	%fd<348>;
	.reg .b64 	%rd<40>;


	ld.param.u64 	%rd19, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_6];
	mov.b32 	%r16, %envreg3;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %tid.x;
	add.s32 	%r20, %r19, %r16;
	mad.lo.s32 	%r21, %r18, %r17, %r20;
	cvt.s64.s32 	%rd1, %r21;
	setp.gt.s32 	%p1, %r21, 4;
	mov.f64 	%fd325, 0d7FFFFFFFE0000000;
	@%p1 bra 	$L__BB0_2;

	shl.b64 	%rd20, %rd1, 3;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.f64 	%fd325, [%rd21];

$L__BB0_2:
	abs.f64 	%fd75, %fd325;
	setp.le.f64 	%p2, %fd75, 0d7FF0000000000000;
	selp.f64 	%fd3, %fd325, 0d0000000000000000, %p2;
	setp.eq.f64 	%p3, %fd3, 0d3FF0000000000000;
	mov.f64 	%fd329, 0d3FF0000000000000;
	@%p3 bra 	$L__BB0_28;

	abs.f64 	%fd4, %fd3;
	setp.gtu.f64 	%p4, %fd4, 0d7FF0000000000000;
	@%p4 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_4;

$L__BB0_27:
	add.f64 	%fd329, %fd3, 0d3FFCAC083126E979;
	bra.uni 	$L__BB0_28;

$L__BB0_4:
	setp.eq.f64 	%p5, %fd3, 0d7FF0000000000000;
	@%p5 bra 	$L__BB0_26;
	bra.uni 	$L__BB0_5;

$L__BB0_26:
	mov.f64 	%fd263, 0d3FFCAC083126E979;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r52}, %fd263;
	}
	setp.gt.s32 	%p28, %r52, -1;
	selp.f64 	%fd329, 0d7FF0000000000000, 0d0000000000000000, %p28;

$L__BB0_28:
	ld.param.u64 	%rd34, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_5];
	cvt.u32.u64 	%r53, %rd1;
	setp.gt.s32 	%p29, %r53, 4;
	add.f64 	%fd23, %fd329, 0d0000000000000000;
	shl.b64 	%rd24, %rd1, 3;
	add.s64 	%rd2, %rd34, %rd24;
	mov.f64 	%fd330, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_30;

	ld.global.f64 	%fd330, [%rd2];

$L__BB0_30:
	abs.f64 	%fd266, %fd330;
	setp.gtu.f64 	%p30, %fd266, 0d7FF0000000000000;
	mov.f64 	%fd339, 0d0000000000000000;
	@%p30 bra 	$L__BB0_52;

	ld.param.u64 	%rd35, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_4];
	add.s64 	%rd3, %rd35, %rd24;
	mov.f64 	%fd331, 0d7FFFFFFFE0000000;
	mov.f64 	%fd332, %fd331;
	@%p29 bra 	$L__BB0_33;

	ld.global.f64 	%fd331, [%rd2];
	ld.global.f64 	%fd332, [%rd3];

$L__BB0_33:
	abs.f64 	%fd270, %fd332;
	setp.gtu.f64 	%p32, %fd270, 0d7FF0000000000000;
	mov.f64 	%fd269, 0d7FF8000000000214;
	mov.f64 	%fd338, %fd269;
	@%p32 bra 	$L__BB0_51;

	ld.param.u64 	%rd36, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_3];
	add.s64 	%rd4, %rd36, %rd24;
	mov.f64 	%fd333, 0d7FFFFFFFE0000000;
	mov.f64 	%fd334, %fd333;
	@%p29 bra 	$L__BB0_36;

	ld.global.f64 	%fd333, [%rd3];
	ld.global.f64 	%fd334, [%rd4];

$L__BB0_36:
	abs.f64 	%fd273, %fd334;
	setp.le.f64 	%p34, %fd273, 0d7FF0000000000000;
	@%p34 bra 	$L__BB0_42;

	mov.f64 	%fd335, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_39;

	ld.global.f64 	%fd335, [%rd3];

$L__BB0_39:
	abs.f64 	%fd275, %fd335;
	setp.gtu.f64 	%p36, %fd275, 0d7FF0000000000000;
	mov.f64 	%fd338, 0d0000000000000000;
	@%p36 bra 	$L__BB0_42;

	@%p29 bra 	$L__BB0_51;

	ld.global.f64 	%fd278, [%rd3];
	setp.neu.f64 	%p38, %fd278, 0d0000000000000000;
	@%p38 bra 	$L__BB0_51;

$L__BB0_42:
	mov.f64 	%fd336, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_44;

	ld.global.f64 	%fd336, [%rd4];

$L__BB0_44:
	abs.f64 	%fd280, %fd336;
	setp.gtu.f64 	%p40, %fd280, 0d7FF0000000000000;
	@%p40 bra 	$L__BB0_49;
	bra.uni 	$L__BB0_45;

$L__BB0_49:
	setp.eq.f64 	%p43, %fd333, 0d0000000000000000;
	mov.f64 	%fd338, %fd269;
	@%p43 bra 	$L__BB0_51;

	rcp.rn.f64 	%fd338, %fd333;
	bra.uni 	$L__BB0_51;

$L__BB0_45:
	setp.eq.f64 	%p41, %fd333, 0d0000000000000000;
	mov.f64 	%fd338, %fd269;
	@%p41 bra 	$L__BB0_51;

	mov.f64 	%fd337, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_48;

	ld.global.f64 	%fd337, [%rd4];

$L__BB0_48:
	div.rn.f64 	%fd338, %fd337, %fd333;

$L__BB0_51:
	mul.f64 	%fd339, %fd331, %fd338;

$L__BB0_52:
	ld.param.u64 	%rd37, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_2];
	add.s64 	%rd5, %rd37, %rd24;
	mov.f64 	%fd340, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_54;

	ld.global.f64 	%fd340, [%rd5];

$L__BB0_54:
	abs.f64 	%fd286, %fd340;
	setp.gtu.f64 	%p45, %fd286, 0d7FF0000000000000;
	mov.f64 	%fd342, 0d0000000000000000;
	@%p45 bra 	$L__BB0_58;

	mov.f64 	%fd341, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_57;

	ld.global.f64 	%fd341, [%rd5];

$L__BB0_57:
	add.f64 	%fd342, %fd341, 0d0000000000000000;

$L__BB0_58:
	ld.param.u64 	%rd38, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_1];
	add.s64 	%rd6, %rd38, %rd24;
	mov.f64 	%fd343, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_60;

	ld.global.f64 	%fd343, [%rd6];

$L__BB0_60:
	abs.f64 	%fd289, %fd343;
	setp.gtu.f64 	%p48, %fd289, 0d7FF0000000000000;
	@%p48 bra 	$L__BB0_78;
	bra.uni 	$L__BB0_61;

$L__BB0_78:
	add.f64 	%fd345, %fd342, 0d0000000000000000;
	bra.uni 	$L__BB0_79;

$L__BB0_61:
	mov.f64 	%fd344, 0d7FFFFFFFE0000000;
	@%p29 bra 	$L__BB0_63;

	ld.global.f64 	%fd344, [%rd6];

$L__BB0_63:
	setp.gt.f64 	%p50, %fd342, 0d0000000000000000;
	setp.lt.f64 	%p51, %fd344, 0d0000000000000000;
	and.pred  	%p52, %p50, %p51;
	@%p52 bra 	$L__BB0_65;

	setp.geu.f64 	%p53, %fd342, 0d0000000000000000;
	setp.leu.f64 	%p54, %fd344, 0d0000000000000000;
	or.pred  	%p55, %p53, %p54;
	@%p55 bra 	$L__BB0_77;

$L__BB0_65:
	neg.f64 	%fd55, %fd342;
	setp.eq.f64 	%p56, %fd344, %fd55;
	mov.f64 	%fd345, 0d0000000000000000;
	@%p56 bra 	$L__BB0_79;

	setp.eq.f64 	%p57, %fd344, 0d0000000000000000;
	setp.eq.f64 	%p58, %fd342, 0d8000000000000000;
	or.pred  	%p59, %p58, %p57;
	@%p59 bra 	$L__BB0_77;

	add.f64 	%fd292, %fd342, %fd344;
	abs.f64 	%fd56, %fd292;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r64}, %fd56;
	}
	and.b32  	%r65, %r64, 2146435072;
	setp.eq.s32 	%p60, %r65, 2146435072;
	@%p60 bra 	$L__BB0_77;

	abs.f64 	%fd57, %fd344;
	mul.f64 	%fd293, %fd57, 0d3D30000000000000;
	setp.gt.f64 	%p61, %fd56, %fd293;
	@%p61 bra 	$L__BB0_77;

	abs.f64 	%fd58, %fd55;
	mul.f64 	%fd294, %fd58, 0d3D30000000000000;
	setp.gt.f64 	%p62, %fd56, %fd294;
	@%p62 bra 	$L__BB0_77;

	setp.gtu.f64 	%p63, %fd56, 0d433FFFFFFFFFFFFF;
	@%p63 bra 	$L__BB0_76;

	cvt.rzi.s64.f64 	%rd7, %fd56;
	setp.gt.s64 	%p64, %rd7, 9007199254740991;
	@%p64 bra 	$L__BB0_76;

	cvt.rn.f64.s64 	%fd295, %rd7;
	setp.ne.f64 	%p65, %fd56, %fd295;
	setp.gtu.f64 	%p66, %fd57, 0d433FFFFFFFFFFFFF;
	or.pred  	%p67, %p65, %p66;
	@%p67 bra 	$L__BB0_76;

	cvt.rzi.s64.f64 	%rd8, %fd57;
	setp.gt.s64 	%p68, %rd8, 9007199254740991;
	@%p68 bra 	$L__BB0_76;

	cvt.rn.f64.s64 	%fd296, %rd8;
	setp.ne.f64 	%p69, %fd57, %fd296;
	setp.gtu.f64 	%p70, %fd58, 0d433FFFFFFFFFFFFF;
	or.pred  	%p71, %p69, %p70;
	@%p71 bra 	$L__BB0_76;

	cvt.rzi.s64.f64 	%rd29, %fd58;
	setp.lt.s64 	%p72, %rd29, 9007199254740992;
	cvt.rn.f64.s64 	%fd297, %rd29;
	setp.equ.f64 	%p73, %fd58, %fd297;
	and.pred  	%p74, %p72, %p73;
	@%p74 bra 	$L__BB0_77;

$L__BB0_76:
	mul.f64 	%fd299, %fd57, 0d3CF0000000000000;
	setp.lt.f64 	%p75, %fd56, %fd299;
	mul.f64 	%fd300, %fd58, 0d3CF0000000000000;
	setp.lt.f64 	%p76, %fd56, %fd300;
	and.pred  	%p77, %p75, %p76;
	@%p77 bra 	$L__BB0_79;

$L__BB0_77:
	add.f64 	%fd345, %fd342, %fd344;

$L__BB0_79:
	setp.lt.f64 	%p78, %fd339, 0d0000000000000000;
	setp.lt.f64 	%p79, %fd345, 0d0000000000000000;
	and.pred  	%p80, %p78, %p79;
	@%p80 bra 	$L__BB0_81;

	setp.leu.f64 	%p81, %fd345, 0d0000000000000000;
	setp.leu.f64 	%p82, %fd339, 0d0000000000000000;
	or.pred  	%p83, %p82, %p81;
	@%p83 bra 	$L__BB0_93;

$L__BB0_81:
	setp.eq.f64 	%p84, %fd345, %fd339;
	mov.f64 	%fd346, 0d0000000000000000;
	@%p84 bra 	$L__BB0_94;

	setp.eq.f64 	%p85, %fd345, 0d0000000000000000;
	setp.eq.f64 	%p86, %fd339, 0d0000000000000000;
	or.pred  	%p87, %p86, %p85;
	@%p87 bra 	$L__BB0_93;

	sub.f64 	%fd302, %fd345, %fd339;
	abs.f64 	%fd62, %fd302;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd62;
	}
	and.b32  	%r67, %r66, 2146435072;
	setp.eq.s32 	%p88, %r67, 2146435072;
	@%p88 bra 	$L__BB0_93;

	abs.f64 	%fd63, %fd345;
	mul.f64 	%fd303, %fd63, 0d3D30000000000000;
	setp.gt.f64 	%p89, %fd62, %fd303;
	@%p89 bra 	$L__BB0_93;

	abs.f64 	%fd64, %fd339;
	mul.f64 	%fd304, %fd64, 0d3D30000000000000;
	setp.gt.f64 	%p90, %fd62, %fd304;
	@%p90 bra 	$L__BB0_93;

	setp.gtu.f64 	%p91, %fd62, 0d433FFFFFFFFFFFFF;
	@%p91 bra 	$L__BB0_92;

	cvt.rzi.s64.f64 	%rd9, %fd62;
	setp.gt.s64 	%p92, %rd9, 9007199254740991;
	@%p92 bra 	$L__BB0_92;

	cvt.rn.f64.s64 	%fd305, %rd9;
	setp.ne.f64 	%p93, %fd62, %fd305;
	setp.gtu.f64 	%p94, %fd63, 0d433FFFFFFFFFFFFF;
	or.pred  	%p95, %p93, %p94;
	@%p95 bra 	$L__BB0_92;

	cvt.rzi.s64.f64 	%rd10, %fd63;
	setp.gt.s64 	%p96, %rd10, 9007199254740991;
	@%p96 bra 	$L__BB0_92;

	cvt.rn.f64.s64 	%fd306, %rd10;
	setp.ne.f64 	%p97, %fd63, %fd306;
	setp.gtu.f64 	%p98, %fd64, 0d433FFFFFFFFFFFFF;
	or.pred  	%p99, %p97, %p98;
	@%p99 bra 	$L__BB0_92;

	cvt.rzi.s64.f64 	%rd30, %fd64;
	setp.lt.s64 	%p100, %rd30, 9007199254740992;
	cvt.rn.f64.s64 	%fd307, %rd30;
	setp.equ.f64 	%p101, %fd64, %fd307;
	and.pred  	%p102, %p100, %p101;
	@%p102 bra 	$L__BB0_93;

$L__BB0_92:
	mul.f64 	%fd309, %fd63, 0d3CF0000000000000;
	setp.lt.f64 	%p103, %fd62, %fd309;
	mul.f64 	%fd310, %fd64, 0d3CF0000000000000;
	setp.lt.f64 	%p104, %fd62, %fd310;
	and.pred  	%p105, %p103, %p104;
	@%p105 bra 	$L__BB0_94;

$L__BB0_93:
	sub.f64 	%fd346, %fd345, %fd339;

$L__BB0_94:
	setp.gt.f64 	%p106, %fd23, 0d0000000000000000;
	setp.lt.f64 	%p107, %fd346, 0d0000000000000000;
	and.pred  	%p108, %p106, %p107;
	@%p108 bra 	$L__BB0_96;

	setp.geu.f64 	%p109, %fd23, 0d0000000000000000;
	setp.leu.f64 	%p110, %fd346, 0d0000000000000000;
	or.pred  	%p111, %p109, %p110;
	@%p111 bra 	$L__BB0_108;

$L__BB0_96:
	neg.f64 	%fd67, %fd23;
	setp.eq.f64 	%p112, %fd346, %fd67;
	mov.f64 	%fd347, 0d0000000000000000;
	@%p112 bra 	$L__BB0_109;

	setp.eq.f64 	%p113, %fd346, 0d0000000000000000;
	setp.eq.f64 	%p114, %fd23, 0d8000000000000000;
	or.pred  	%p115, %p114, %p113;
	@%p115 bra 	$L__BB0_108;

	add.f64 	%fd312, %fd23, %fd346;
	abs.f64 	%fd68, %fd312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r68}, %fd68;
	}
	and.b32  	%r69, %r68, 2146435072;
	setp.eq.s32 	%p116, %r69, 2146435072;
	@%p116 bra 	$L__BB0_108;

	abs.f64 	%fd69, %fd346;
	mul.f64 	%fd313, %fd69, 0d3D30000000000000;
	setp.gt.f64 	%p117, %fd68, %fd313;
	@%p117 bra 	$L__BB0_108;

	abs.f64 	%fd70, %fd67;
	mul.f64 	%fd314, %fd70, 0d3D30000000000000;
	setp.gt.f64 	%p118, %fd68, %fd314;
	@%p118 bra 	$L__BB0_108;

	setp.gtu.f64 	%p119, %fd68, 0d433FFFFFFFFFFFFF;
	@%p119 bra 	$L__BB0_107;

	cvt.rzi.s64.f64 	%rd11, %fd68;
	setp.gt.s64 	%p120, %rd11, 9007199254740991;
	@%p120 bra 	$L__BB0_107;

	cvt.rn.f64.s64 	%fd315, %rd11;
	setp.ne.f64 	%p121, %fd68, %fd315;
	setp.gtu.f64 	%p122, %fd69, 0d433FFFFFFFFFFFFF;
	or.pred  	%p123, %p121, %p122;
	@%p123 bra 	$L__BB0_107;

	cvt.rzi.s64.f64 	%rd12, %fd69;
	setp.gt.s64 	%p124, %rd12, 9007199254740991;
	@%p124 bra 	$L__BB0_107;

	cvt.rn.f64.s64 	%fd316, %rd12;
	setp.ne.f64 	%p125, %fd69, %fd316;
	setp.gtu.f64 	%p126, %fd70, 0d433FFFFFFFFFFFFF;
	or.pred  	%p127, %p125, %p126;
	@%p127 bra 	$L__BB0_107;

	cvt.rzi.s64.f64 	%rd31, %fd70;
	setp.lt.s64 	%p128, %rd31, 9007199254740992;
	cvt.rn.f64.s64 	%fd317, %rd31;
	setp.equ.f64 	%p129, %fd70, %fd317;
	and.pred  	%p130, %p128, %p129;
	@%p130 bra 	$L__BB0_108;

$L__BB0_107:
	mul.f64 	%fd319, %fd69, 0d3CF0000000000000;
	setp.lt.f64 	%p131, %fd68, %fd319;
	mul.f64 	%fd320, %fd70, 0d3CF0000000000000;
	setp.lt.f64 	%p132, %fd68, %fd320;
	and.pred  	%p133, %p131, %p132;
	@%p133 bra 	$L__BB0_109;

$L__BB0_108:
	add.f64 	%fd347, %fd23, %fd346;

$L__BB0_109:
	ld.param.u64 	%rd39, [DynamicKernel_nop_fsum_fsub_fsum_fmul_fdiv_Power_param_0];
	add.s64 	%rd33, %rd39, %rd24;
	st.global.f64 	[%rd33], %fd347;
	ret;

$L__BB0_5:
	mov.f64 	%fd76, 0d3FFCAC083126E979;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd76;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd76;
	}
	and.b32  	%r24, %r23, 2147483647;
	setp.ne.s32 	%p6, %r24, 2146435072;
	setp.ne.s32 	%p7, %r22, 0;
	or.pred  	%p8, %p7, %p6;
	@%p8 bra 	$L__BB0_8;
	bra.uni 	$L__BB0_6;

$L__BB0_8:
	mov.f64 	%fd79, 0d3FE0000000000000;
	mul.rn.f64 	%fd80, %fd79, %fd76;
	cvt.rzi.f64.f64 	%fd81, %fd80;
	mov.f64 	%fd82, 0d4000000000000000;
	mul.rn.f64 	%fd83, %fd82, %fd81;
	sub.f64 	%fd84, %fd76, %fd83;
	abs.f64 	%fd6, %fd84;
	setp.eq.f64 	%p11, %fd3, 0d0000000000000000;
	@%p11 bra 	$L__BB0_25;
	bra.uni 	$L__BB0_9;

$L__BB0_25:
	setp.eq.f64 	%p27, %fd6, 0d3FF0000000000000;
	selp.f64 	%fd329, %fd3, 0d0000000000000000, %p27;
	bra.uni 	$L__BB0_28;

$L__BB0_6:
	setp.eq.f64 	%p9, %fd3, 0dBFF0000000000000;
	@%p9 bra 	$L__BB0_28;

	setp.gt.f64 	%p10, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd329, 0d7FF0000000000000, 0d0000000000000000, %p10;
	bra.uni 	$L__BB0_28;

$L__BB0_9:
	setp.eq.f64 	%p12, %fd3, 0dFFF0000000000000;
	@%p12 bra 	$L__BB0_23;
	bra.uni 	$L__BB0_10;

$L__BB0_23:
	setp.neu.f64 	%p26, %fd6, 0d3FF0000000000000;
	mov.f64 	%fd329, 0d7FF0000000000000;
	@%p26 bra 	$L__BB0_28;

	mov.f64 	%fd329, 0dFFF0000000000000;
	bra.uni 	$L__BB0_28;

$L__BB0_10:
	setp.geu.f64 	%p13, %fd3, 0d0000000000000000;
	@%p13 bra 	$L__BB0_12;

	mov.f64 	%fd86, 0d3FFCAC083126E979;
	cvt.rzi.f64.f64 	%fd87, %fd86;
	setp.neu.f64 	%p14, %fd87, 0d3FFCAC083126E979;
	mov.f64 	%fd329, 0dFFF8000000000000;
	@%p14 bra 	$L__BB0_28;

$L__BB0_12:
	// begin inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r72}, %fd4; 
	}
	// end inline asm
	// begin inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r71, hi}, %fd4; 
	}
	// end inline asm
	bfe.u32 	%r73, %r72, 20, 11;
	setp.ne.s32 	%p15, %r73, 0;
	@%p15 bra 	$L__BB0_14;

	mov.f64 	%fd92, 0d4350000000000000;
	mul.rn.f64 	%fd91, %fd4, %fd92;
	// begin inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r72}, %fd91; 
	}
	// end inline asm
	// begin inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r71, hi}, %fd91; 
	}
	// end inline asm
	bfe.u32 	%r29, %r72, 20, 11;
	add.s32 	%r73, %r29, -54;

$L__BB0_14:
	add.s32 	%r74, %r73, -1023;
	and.b32  	%r32, %r72, -2146435073;
	or.b32  	%r31, %r32, 1072693248;
	// begin inline asm
	mov.b64 	%fd326, {%r71, %r31};
	// end inline asm
	setp.lt.u32 	%p16, %r31, 1073127583;
	@%p16 bra 	$L__BB0_16;

	// begin inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r33, hi}, %fd326; 
	}
	// end inline asm
	// begin inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r34}, %fd326; 
	}
	// end inline asm
	add.s32 	%r36, %r34, -1048576;
	// begin inline asm
	mov.b64 	%fd326, {%r33, %r36};
	// end inline asm
	add.s32 	%r74, %r73, -1022;

$L__BB0_16:
	add.f64 	%fd181, %fd326, 0d3FF0000000000000;
	mov.f64 	%fd182, 0d3FF0000000000000;
	rcp.rn.f64 	%fd183, %fd181;
	add.f64 	%fd123, %fd326, 0dBFF0000000000000;
	mul.rn.f64 	%fd184, %fd123, %fd183;
	add.f64 	%fd171, %fd184, %fd184;
	mul.rn.f64 	%fd119, %fd171, %fd171;
	mov.f64 	%fd98, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd100, 0d3ED0F5D241AD3B5A;
	// begin inline asm
	fma.rn.f64 	%fd97, %fd98, %fd119, %fd100;
	// end inline asm
	mov.f64 	%fd104, 0d3EF3B20A75488A3F;
	// begin inline asm
	fma.rn.f64 	%fd101, %fd97, %fd119, %fd104;
	// end inline asm
	mov.f64 	%fd108, 0d3F1745CDE4FAECD5;
	// begin inline asm
	fma.rn.f64 	%fd105, %fd101, %fd119, %fd108;
	// end inline asm
	mov.f64 	%fd112, 0d3F3C71C7258A578B;
	// begin inline asm
	fma.rn.f64 	%fd109, %fd105, %fd119, %fd112;
	// end inline asm
	mov.f64 	%fd116, 0d3F6249249242B910;
	// begin inline asm
	fma.rn.f64 	%fd113, %fd109, %fd119, %fd116;
	// end inline asm
	mov.f64 	%fd120, 0d3F89999999999DFB;
	// begin inline asm
	fma.rn.f64 	%fd117, %fd113, %fd119, %fd120;
	// end inline asm
	mul.rn.f64 	%fd185, %fd117, %fd119;
	sub.f64 	%fd186, %fd123, %fd171;
	mov.f64 	%fd187, 0d4000000000000000;
	mul.rn.f64 	%fd124, %fd187, %fd186;
	neg.f64 	%fd122, %fd171;
	// begin inline asm
	fma.rn.f64 	%fd121, %fd122, %fd123, %fd124;
	// end inline asm
	mul.rn.f64 	%fd167, %fd183, %fd121;
	add.f64 	%fd188, %fd185, 0d3FB5555555555555;
	mov.f64 	%fd189, 0d3FB5555555555555;
	sub.f64 	%fd190, %fd189, %fd188;
	add.f64 	%fd191, %fd185, %fd190;
	add.f64 	%fd192, %fd191, 0d0000000000000000;
	add.f64 	%fd193, %fd192, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd134, %fd188, %fd193;
	sub.f64 	%fd194, %fd188, %fd134;
	add.f64 	%fd138, %fd193, %fd194;
	mul.rn.f64 	%fd195, %fd134, %fd171;
	neg.f64 	%fd128, %fd195;
	// begin inline asm
	fma.rn.f64 	%fd125, %fd134, %fd171, %fd128;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd129, %fd138, %fd167, %fd125;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd133, %fd134, %fd167, %fd129;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd137, %fd138, %fd171, %fd133;
	// end inline asm
	add.f64 	%fd150, %fd195, %fd137;
	sub.f64 	%fd196, %fd195, %fd150;
	add.f64 	%fd154, %fd137, %fd196;
	mul.rn.f64 	%fd197, %fd150, %fd171;
	neg.f64 	%fd144, %fd197;
	// begin inline asm
	fma.rn.f64 	%fd141, %fd150, %fd171, %fd144;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd145, %fd154, %fd167, %fd141;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd149, %fd150, %fd167, %fd145;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd153, %fd154, %fd171, %fd149;
	// end inline asm
	add.f64 	%fd166, %fd197, %fd153;
	sub.f64 	%fd198, %fd197, %fd166;
	add.f64 	%fd170, %fd153, %fd198;
	mul.rn.f64 	%fd199, %fd166, %fd171;
	neg.f64 	%fd160, %fd199;
	// begin inline asm
	fma.rn.f64 	%fd157, %fd166, %fd171, %fd160;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd161, %fd170, %fd167, %fd157;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd165, %fd166, %fd167, %fd161;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd169, %fd170, %fd171, %fd165;
	// end inline asm
	add.f64 	%fd200, %fd199, %fd169;
	sub.f64 	%fd201, %fd199, %fd200;
	add.f64 	%fd202, %fd169, %fd201;
	add.f64 	%fd203, %fd171, %fd200;
	sub.f64 	%fd204, %fd171, %fd203;
	add.f64 	%fd205, %fd200, %fd204;
	add.f64 	%fd206, %fd202, %fd205;
	add.f64 	%fd207, %fd167, %fd206;
	add.f64 	%fd208, %fd203, %fd207;
	sub.f64 	%fd209, %fd203, %fd208;
	add.f64 	%fd210, %fd207, %fd209;
	cvt.rn.f64.s32 	%fd211, %r74;
	mov.f64 	%fd212, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd213, %fd211, %fd212;
	mov.f64 	%fd214, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd215, %fd211, %fd214;
	add.f64 	%fd216, %fd213, %fd208;
	sub.f64 	%fd217, %fd213, %fd216;
	add.f64 	%fd218, %fd208, %fd217;
	add.f64 	%fd219, %fd210, %fd218;
	add.f64 	%fd220, %fd215, %fd219;
	add.f64 	%fd174, %fd216, %fd220;
	sub.f64 	%fd221, %fd216, %fd174;
	add.f64 	%fd178, %fd220, %fd221;
	mov.f64 	%fd179, 0d3FFCAC083126E979;
	mul.rn.f64 	%fd222, %fd174, %fd179;
	neg.f64 	%fd176, %fd222;
	// begin inline asm
	fma.rn.f64 	%fd173, %fd174, %fd179, %fd176;
	// end inline asm
	// begin inline asm
	fma.rn.f64 	%fd177, %fd178, %fd179, %fd173;
	// end inline asm
	add.f64 	%fd10, %fd222, %fd177;
	sub.f64 	%fd223, %fd222, %fd10;
	add.f64 	%fd11, %fd177, %fd223;
	mov.f64 	%fd224, 0d4338000000000000;
	mov.f64 	%fd225, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd226, %fd10, %fd225, %fd224;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd226;
	}
	mov.f64 	%fd227, 0dC338000000000000;
	add.rn.f64 	%fd228, %fd226, %fd227;
	mov.f64 	%fd229, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd230, %fd228, %fd229, %fd10;
	mov.f64 	%fd231, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd232, %fd228, %fd231, %fd230;
	mov.f64 	%fd233, 0d3E928AF3FCA213EA;
	mov.f64 	%fd234, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd235, %fd234, %fd232, %fd233;
	mov.f64 	%fd236, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd237, %fd235, %fd232, %fd236;
	mov.f64 	%fd238, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd239, %fd237, %fd232, %fd238;
	mov.f64 	%fd240, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd241, %fd239, %fd232, %fd240;
	mov.f64 	%fd242, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd243, %fd241, %fd232, %fd242;
	mov.f64 	%fd244, 0d3F81111111122322;
	fma.rn.f64 	%fd245, %fd243, %fd232, %fd244;
	mov.f64 	%fd246, 0d3FA55555555502A1;
	fma.rn.f64 	%fd247, %fd245, %fd232, %fd246;
	mov.f64 	%fd248, 0d3FC5555555555511;
	fma.rn.f64 	%fd249, %fd247, %fd232, %fd248;
	mov.f64 	%fd250, 0d3FE000000000000B;
	fma.rn.f64 	%fd251, %fd249, %fd232, %fd250;
	fma.rn.f64 	%fd252, %fd251, %fd232, %fd182;
	fma.rn.f64 	%fd253, %fd252, %fd232, %fd182;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r14, %temp}, %fd253;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd253;
	}
	shl.b32 	%r37, %r13, 20;
	add.s32 	%r38, %r15, %r37;
	mov.b64 	%fd329, {%r14, %r38};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd10;
	}
	mov.b32 	%f2, %r39;
	abs.f32 	%f1, %f2;
	setp.lt.f32 	%p17, %f1, 0f4086232B;
	@%p17 bra 	$L__BB0_19;

	setp.lt.f64 	%p18, %fd10, 0d0000000000000000;
	add.f64 	%fd254, %fd10, 0d7FF0000000000000;
	selp.f64 	%fd329, 0d0000000000000000, %fd254, %p18;
	setp.geu.f32 	%p19, %f1, 0f40874800;
	@%p19 bra 	$L__BB0_19;

	mov.f64 	%fd324, 0d4338000000000000;
	mov.f64 	%fd323, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd322, %fd10, %fd323, %fd324;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r70, %temp}, %fd322;
	}
	shr.u32 	%r40, %r70, 31;
	add.s32 	%r41, %r70, %r40;
	shr.s32 	%r42, %r41, 1;
	shl.b32 	%r43, %r42, 20;
	add.s32 	%r44, %r15, %r43;
	mov.b64 	%fd255, {%r14, %r44};
	sub.s32 	%r45, %r70, %r42;
	shl.b32 	%r46, %r45, 20;
	add.s32 	%r47, %r46, 1072693248;
	mov.u32 	%r48, 0;
	mov.b64 	%fd256, {%r48, %r47};
	mul.f64 	%fd329, %fd255, %fd256;

$L__BB0_19:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd329;
	}
	and.b32  	%r50, %r49, 2147483647;
	setp.eq.s32 	%p20, %r50, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd329;
	}
	setp.eq.s32 	%p21, %r51, 0;
	and.pred  	%p22, %p21, %p20;
	@%p22 bra 	$L__BB0_21;

	// begin inline asm
	fma.rn.f64 	%fd329, %fd329, %fd11, %fd329;
	// end inline asm

$L__BB0_21:
	setp.neu.f64 	%p23, %fd6, 0d3FF0000000000000;
	or.pred  	%p25, %p13, %p23;
	@%p25 bra 	$L__BB0_28;

	mov.b64 	%rd22, %fd329;
	xor.b64  	%rd23, %rd22, -9223372036854775808;
	mov.b64 	%fd329, %rd23;
	bra.uni 	$L__BB0_28;

}

  